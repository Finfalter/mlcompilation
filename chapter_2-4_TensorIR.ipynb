{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Machine Learning Compilation](https://mlc.ai/chapter_introduction/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook relates to the corresponding course.\n",
    "\n",
    "* The first half of the notebook closely corresponds to [2.4. TensorIR: Tensor Program Abstraction Case Study](https://mlc.ai/chapter_tensor_program/case_study.html).\n",
    "* The second half is a free interpretation of the quest __how to optimize an operator.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import tir as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = \"float32\"\n",
    "a_np = np.random.rand(128, 128).astype(dtype)\n",
    "b_np = np.random.rand(128, 128).astype(dtype)\n",
    "# a @ b is equivalent to np.matmul(a, b)\n",
    "c_mm_relu = np.maximum(a_np @ b_np, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.runtime.ndarray.NDArray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_nd = tvm.nd.array(a_np)\n",
    "b_nd = tvm.nd.array(b_np)\n",
    "c_nd = tvm.nd.empty((128, 128), dtype=\"float32\")\n",
    "type(c_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyModule:\n",
    "    @T.prim_func\n",
    "    def mm_relu(A: T.Buffer((128, 128), \"float32\"),\n",
    "                B: T.Buffer((128, 128), \"float32\"),\n",
    "                C: T.Buffer((128, 128), \"float32\")):\n",
    "        T.func_attr({\"global_symbol\": \"mm_relu\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer((128, 128), dtype=\"float32\")\n",
    "        for i, j, k in T.grid(128, 128, 128):\n",
    "            with T.block(\"Y\"):\n",
    "                vi = T.axis.spatial(128, i)\n",
    "                vj = T.axis.spatial(128, j)\n",
    "                vk = T.axis.reduce(128, k)\n",
    "                with T.init():\n",
    "                    Y[vi, vj] = T.float32(0)\n",
    "                Y[vi, vj] = Y[vi, vj] + A[vi, vk] * B[vk, vj]\n",
    "        for i, j in T.grid(128, 128):\n",
    "            with T.block(\"C\"):\n",
    "                vi = T.axis.spatial(128, i)\n",
    "                vj = T.axis.spatial(128, j)\n",
    "                C[vi, vj] = T.max(Y[vi, vj], T.float32(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">mm_relu</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), C: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        Y <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Y&quot;</span>):\n",
       "                vi, vj, vk <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[vi, vk], B[vk, vj])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Y[vi, vj])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[vi, vk] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[vk, vj]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;C&quot;</span>):\n",
       "                vi, vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i, j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(Y[vi, vj])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(C[vi, vj])\n",
       "                C[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(Y[vi, vj], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MyModule.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's modify the way we loop through the structure.\n",
    "`jfactor` determines how to balance between `j0` and `j1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(mod, jfactor):\n",
    "    sch = tvm.tir.Schedule(mod)\n",
    "    block_Y = sch.get_block(\"Y\", func_name=\"mm_relu\")\n",
    "    i, j, k = sch.get_loops(block_Y)\n",
    "    j0, j1 = sch.split(j, factors=[None, jfactor])\n",
    "    sch.reorder(j0, k, j1)\n",
    "    block_C = sch.get_block(\"C\", \"mm_relu\")\n",
    "    sch.reverse_compute_at(block_C, j0)\n",
    "    return sch.mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`check_identity` makes sure we always adhere to the result of the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_identity(rt_lib):\n",
    "   #rt_lib_after = tvm.build(mod, target=\"llvm\")\n",
    "   rt_lib[\"mm_relu\"](a_nd, b_nd, c_nd)\n",
    "   np.testing.assert_allclose(c_mm_relu, c_nd.numpy(), rtol=1e-5)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each configuration, measure the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(jf, performance):\n",
    "    mod_transformed = transform(MyModule, jfactor=jf)\n",
    "    rt_lib_transformed = tvm.build(mod_transformed, \"llvm\")\n",
    "    #check_identity(mod_transformed)\n",
    "    check_identity(rt_lib_transformed)\n",
    "\n",
    "    f_timer_transformed = rt_lib_transformed.time_evaluator(\"mm_relu\", tvm.cpu())\n",
    "    t = f_timer_transformed(a_nd, b_nd, c_nd).mean\n",
    "    #print(\"Time cost of transformed for jfactor=={}: {} sec\".format(jf, t))\n",
    "    performance[jf] = (t, mod_transformed)\n",
    "    return performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {}\n",
    "for i in range(1, 128, 1):\n",
    "   performance = benchmark(i, performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jfactor: 32, t: 0.00015303000000000002s\n",
      "jfactor: 12, t: 0.00020095s\n",
      "jfactor: 64, t: 0.00022651s\n",
      "jfactor: 10, t: 0.00023535s\n",
      "jfactor: 8, t: 0.00023564s\n",
      "jfactor: 13, t: 0.00030172s\n",
      "jfactor: 4, t: 0.00038056s\n",
      "jfactor: 15, t: 0.00039287999999999997s\n",
      "jfactor: 16, t: 0.0004205199999999999s\n",
      "jfactor: 20, t: 0.00042167s\n",
      "jfactor: 14, t: 0.00042214s\n",
      "jfactor: 18, t: 0.00042917s\n",
      "jfactor: 19, t: 0.00044241s\n",
      "jfactor: 11, t: 0.00045303s\n",
      "jfactor: 17, t: 0.00053091s\n",
      "jfactor: 6, t: 0.00054278s\n",
      "jfactor: 3, t: 0.0006664799999999999s\n",
      "jfactor: 7, t: 0.00067649s\n",
      "jfactor: 9, t: 0.00071099s\n",
      "jfactor: 5, t: 0.00071331s\n",
      "jfactor: 2, t: 0.00090735s\n",
      "jfactor: 35, t: 0.00109172s\n",
      "jfactor: 48, t: 0.00112165s\n",
      "jfactor: 34, t: 0.00114607s\n",
      "jfactor: 46, t: 0.00114631s\n",
      "jfactor: 36, t: 0.0011612399999999998s\n",
      "jfactor: 21, t: 0.0011694000000000001s\n",
      "jfactor: 33, t: 0.0011766699999999999s\n",
      "jfactor: 37, t: 0.00119457s\n",
      "jfactor: 44, t: 0.00121251s\n",
      "jfactor: 68, t: 0.00121856s\n",
      "jfactor: 38, t: 0.0012265700000000002s\n",
      "jfactor: 50, t: 0.00124455s\n",
      "jfactor: 39, t: 0.00125889s\n",
      "jfactor: 45, t: 0.00127597s\n",
      "jfactor: 41, t: 0.00128911s\n",
      "jfactor: 66, t: 0.00129621s\n",
      "jfactor: 70, t: 0.00130042s\n",
      "jfactor: 76, t: 0.0013369500000000002s\n",
      "jfactor: 43, t: 0.00136249s\n",
      "jfactor: 26, t: 0.00137035s\n",
      "jfactor: 67, t: 0.00137187s\n",
      "jfactor: 72, t: 0.00139261s\n",
      "jfactor: 74, t: 0.00139285s\n",
      "jfactor: 53, t: 0.0013964000000000001s\n",
      "jfactor: 63, t: 0.0014281200000000002s\n",
      "jfactor: 61, t: 0.00142825s\n",
      "jfactor: 78, t: 0.0014363899999999998s\n",
      "jfactor: 47, t: 0.00144028s\n",
      "jfactor: 52, t: 0.00144107s\n",
      "jfactor: 42, t: 0.0014419600000000002s\n",
      "jfactor: 69, t: 0.00144522s\n",
      "jfactor: 54, t: 0.00144696s\n",
      "jfactor: 77, t: 0.0014739900000000001s\n",
      "jfactor: 56, t: 0.00148128s\n",
      "jfactor: 49, t: 0.00149354s\n",
      "jfactor: 40, t: 0.00150083s\n",
      "jfactor: 58, t: 0.0015042s\n",
      "jfactor: 51, t: 0.00150672s\n",
      "jfactor: 55, t: 0.00150838s\n",
      "jfactor: 75, t: 0.00151043s\n",
      "jfactor: 71, t: 0.00152376s\n",
      "jfactor: 81, t: 0.00153778s\n",
      "jfactor: 90, t: 0.0015543100000000002s\n",
      "jfactor: 80, t: 0.00155706s\n",
      "jfactor: 84, t: 0.00156097s\n",
      "jfactor: 24, t: 0.00159067s\n",
      "jfactor: 86, t: 0.00159177s\n",
      "jfactor: 79, t: 0.00159866s\n",
      "jfactor: 83, t: 0.0016019600000000001s\n",
      "jfactor: 85, t: 0.0016037800000000002s\n",
      "jfactor: 27, t: 0.0016043500000000003s\n",
      "jfactor: 60, t: 0.0016110399999999998s\n",
      "jfactor: 59, t: 0.00161495s\n",
      "jfactor: 57, t: 0.00163799s\n",
      "jfactor: 87, t: 0.0016468099999999999s\n",
      "jfactor: 121, t: 0.0016579999999999998s\n",
      "jfactor: 25, t: 0.0016763200000000002s\n",
      "jfactor: 23, t: 0.0016788s\n",
      "jfactor: 123, t: 0.0016902300000000002s\n",
      "jfactor: 65, t: 0.00170003s\n",
      "jfactor: 29, t: 0.0017137899999999998s\n",
      "jfactor: 28, t: 0.00171617s\n",
      "jfactor: 92, t: 0.0017255299999999999s\n",
      "jfactor: 89, t: 0.0017303699999999997s\n",
      "jfactor: 62, t: 0.0017367s\n",
      "jfactor: 1, t: 0.0017453299999999998s\n",
      "jfactor: 88, t: 0.00175301s\n",
      "jfactor: 93, t: 0.00178619s\n",
      "jfactor: 82, t: 0.0018086999999999999s\n",
      "jfactor: 97, t: 0.0018211899999999999s\n",
      "jfactor: 94, t: 0.00182301s\n",
      "jfactor: 127, t: 0.00182673s\n",
      "jfactor: 96, t: 0.0018314399999999997s\n",
      "jfactor: 95, t: 0.0018356400000000001s\n",
      "jfactor: 91, t: 0.0018407599999999999s\n",
      "jfactor: 73, t: 0.00192913s\n",
      "jfactor: 125, t: 0.0019366000000000001s\n",
      "jfactor: 22, t: 0.0019400799999999998s\n",
      "jfactor: 31, t: 0.00195012s\n",
      "jfactor: 103, t: 0.0019774099999999998s\n",
      "jfactor: 107, t: 0.0019806299999999997s\n",
      "jfactor: 101, t: 0.00198221s\n",
      "jfactor: 102, t: 0.00198359s\n",
      "jfactor: 30, t: 0.00203548s\n",
      "jfactor: 109, t: 0.0020361399999999997s\n",
      "jfactor: 105, t: 0.0020610600000000004s\n",
      "jfactor: 104, t: 0.0020906099999999997s\n",
      "jfactor: 108, t: 0.0020945499999999997s\n",
      "jfactor: 112, t: 0.0021203700000000003s\n",
      "jfactor: 110, t: 0.0021398499999999996s\n",
      "jfactor: 111, t: 0.00216571s\n",
      "jfactor: 106, t: 0.00218232s\n",
      "jfactor: 98, t: 0.00221251s\n",
      "jfactor: 115, t: 0.00223562s\n",
      "jfactor: 100, t: 0.00227671s\n",
      "jfactor: 116, t: 0.00228947s\n",
      "jfactor: 114, t: 0.00233201s\n",
      "jfactor: 117, t: 0.00233901s\n",
      "jfactor: 118, t: 0.00234847s\n",
      "jfactor: 119, t: 0.00236376s\n",
      "jfactor: 99, t: 0.0023827600000000003s\n",
      "jfactor: 113, t: 0.00245809s\n",
      "jfactor: 120, t: 0.0025058700000000003s\n",
      "jfactor: 122, t: 0.00255858s\n",
      "jfactor: 126, t: 0.00269983s\n",
      "jfactor: 124, t: 0.00290464s\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "sorted_dict = dict(sorted(performance.items(), key=operator.itemgetter(1)))\n",
    "\n",
    "for k, v in sorted_dict.items():\n",
    "   print(\"jfactor: {}, t: {}s\".format(k, v[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys with minimum values are: jfactor==32 which takes 0.00015303000000000002s to compute.\n"
     ]
    }
   ],
   "source": [
    "#print(performance)\n",
    "# Using min() + list comprehension + values()\n",
    "# Finding min value keys in dictionary\n",
    "#vals = min(performance.values())\n",
    "times= [x[0] for x in performance.values()]\n",
    "min_t= min(times)\n",
    "res = [key for key in performance if performance[key][0] == min_t]\n",
    " \n",
    "# printing result \n",
    "print(\"Keys with minimum values are: jfactor=={} which takes {}s to compute.\".format(str(res[0]), min_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winner in terms of compute (less is more):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">mm_relu</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), C: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        Y <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i, j_0 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">4</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> k, j_1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">32</span>):\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Y&quot;</span>):\n",
       "                    vi <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, i)\n",
       "                    vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, j_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">32</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> j_1)\n",
       "                    vk <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>reduce(<span style=\"color: #008000\">128</span>, k)\n",
       "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[vi, vk], B[vk, vj])\n",
       "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Y[vi, vj])\n",
       "                    <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                        Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                    Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> Y[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[vi, vk] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[vk, vj]\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> ax0 <span style=\"color: #008000; font-weight: bold\">in</span> range(<span style=\"color: #008000\">32</span>):\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;C&quot;</span>):\n",
       "                    vi <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, i)\n",
       "                    vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">128</span>, j_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">32</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> ax0)\n",
       "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(Y[vi, vj])\n",
       "                    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(C[vi, vj])\n",
       "                    C[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(Y[vi, vj], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The winner in terms of compute (less is more):\")\n",
    "(performance[res[0]][1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "* __TensorIR__ helps to model operators. It also helps to optimize the loop structure (schedule) of these operators.\n",
    "* Optimization is done relative to the underlying hardware. Optimization probably depends on things like cache size(s), tensor dimensions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlcai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
