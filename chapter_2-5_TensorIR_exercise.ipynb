{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2.5. Exercises for TensorIR](https://mlc.ai/chapter_tensor_program/tensorir_exercises.html)\n",
    "\n",
    "Solutions for the proposed exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import tir as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init data\n",
    "a = np.arange(16).reshape(4, 4)\n",
    "b = np.arange(16, 0, -1).reshape(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16, 16, 16, 16],\n",
       "       [16, 16, 16, 16],\n",
       "       [16, 16, 16, 16],\n",
       "       [16, 16, 16, 16]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy version\n",
    "c_np = a + b\n",
    "c_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16, 16, 16, 16],\n",
       "       [16, 16, 16, 16],\n",
       "       [16, 16, 16, 16],\n",
       "       [16, 16, 16, 16]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# low-level numpy version\n",
    "def lnumpy_add(a: np.ndarray, b: np.ndarray, c: np.ndarray):\n",
    "  for i in range(4):\n",
    "    for j in range(4):\n",
    "      c[i, j] = a[i, j] + b[i, j]\n",
    "c_lnumpy = np.empty((4, 4), dtype=np.int64)\n",
    "lnumpy_add(a, b, c_lnumpy)\n",
    "c_lnumpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorIR version\n",
    "@tvm.script.ir_module\n",
    "class MyAdd:\n",
    "  @T.prim_func\n",
    "  def add(A: T.Buffer((4, 4), \"int64\"),\n",
    "          B: T.Buffer((4, 4), \"int64\"),\n",
    "          C: T.Buffer((4, 4), \"int64\")):\n",
    "    T.func_attr({\"global_symbol\": \"add\"})\n",
    "    for i, j in T.grid(4, 4):\n",
    "      with T.block(\"C\"):\n",
    "        vi = T.axis.spatial(4, i)\n",
    "        vj = T.axis.spatial(4, j)\n",
    "        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
    "\n",
    "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
    "a_tvm = tvm.nd.array(a)\n",
    "b_tvm = tvm.nd.array(b)\n",
    "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
    "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
    "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5.1.2. Exercise 1: Broadcast Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init data\n",
    "a = np.arange(16).reshape(4, 4)\n",
    "b = np.arange(4, 0, -1).reshape(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  4,  4,  4],\n",
       "       [ 8,  8,  8,  8],\n",
       "       [12, 12, 12, 12],\n",
       "       [16, 16, 16, 16]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy version\n",
    "c_np = a + b\n",
    "c_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low level numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  4,  4,  4],\n",
       "       [ 8,  8,  8,  8],\n",
       "       [12, 12, 12, 12],\n",
       "       [16, 16, 16, 16]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# low-level numpy version\n",
    "def lnumpy_add_bc(a: np.ndarray, b: np.ndarray, c: np.ndarray):\n",
    "  for i in range(4):\n",
    "    for j in range(4):\n",
    "      c[i, j] = a[i, j] + b[j]\n",
    "c_lnumpy = np.empty((4, 4), dtype=np.int64)\n",
    "lnumpy_add_bc(a, b, c_lnumpy)\n",
    "c_lnumpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorIR version\n",
    "@tvm.script.ir_module\n",
    "class MyAdd:\n",
    "  @T.prim_func\n",
    "  def add(A: T.Buffer((4, 4), \"int64\"),\n",
    "          B: T.Buffer((4), \"int64\"),\n",
    "          C: T.Buffer((4, 4), \"int64\")):\n",
    "    T.func_attr({\"global_symbol\": \"add\"})\n",
    "    for i, j in T.grid(4, 4):\n",
    "      with T.block(\"C\"):\n",
    "        vi = T.axis.spatial(4, i)\n",
    "        vj = T.axis.spatial(4, j)\n",
    "        C[vi, vj] = A[vi, vj] + B[vj]\n",
    "\n",
    "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
    "a_tvm = tvm.nd.array(a)\n",
    "b_tvm = tvm.nd.array(b)\n",
    "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
    "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
    "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5.1.3. Exercise 2: 2D Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, CI, H, W, CO, K = 1, 1, 8, 8, 2, 3\n",
    "OUT_H, OUT_W = H - K + 1, W - K + 1\n",
    "in1 = np.arange(N*CI*H*W).reshape(N, CI, H, W)\n",
    "in2 = np.arange(CO*CI*K*K).reshape(CO, CI, K, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in1[0, 0, 3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8]]],\n",
       "\n",
       "\n",
       "       [[[ 9, 10, 11],\n",
       "         [12, 13, 14],\n",
       "         [15, 16, 17]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 6, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch version\n",
    "data_torch = torch.Tensor(in1)\n",
    "weight_torch = torch.Tensor(in2)\n",
    "conv_torch = torch.nn.functional.conv2d(data_torch, weight_torch)\n",
    "conv_torch = conv_torch.numpy().astype(np.int64)\n",
    "conv_torch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low level numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-level numpy version\n",
    "def lnumpy_conv2d(data: np.ndarray, weight: np.ndarray, H, W, K, CO):\n",
    "  C = np.zeros([CO, OUT_W, OUT_H], dtype=int)\n",
    "  print(data.shape)\n",
    "  print(weight.shape)\n",
    "  for co in range(CO):\n",
    "    for dh in range(H-K+1):\n",
    "      for dw in range(W-K+1):\n",
    "        for r in range(K):\n",
    "          for c in range(K):\n",
    "            #s = s + data[0, 0, c, r] * weight[0, 0, c, r]\n",
    "            C[co, dw, dh] = C[co, dw, dh] + data[0, 0, c+dw, r+dh] * weight[co, 0, c, r]\n",
    "  return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 8, 8)\n",
      "(2, 1, 3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 6, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npconf = lnumpy_conv2d(in1, in2, H, W, K, CO)\n",
    "npconf.shape\n",
    "#np.testing.assert_allclose(npconv, conv_torch, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO:__ generalize the loop in that each `0` is replaced by a respective parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyConv:\n",
    "   @T.prim_func\n",
    "   def conv (A: T.Buffer((N, CI, H, W),      \"int64\"),\n",
    "             B: T.Buffer((CO, CI, K, K),     \"int64\"),\n",
    "             C: T.Buffer((N, CO, OUT_H, OUT_W), \"int64\")):\n",
    "      T.func_attr({\"global_symbol\": \"conv\", \"tir.noalias\": True})\n",
    "      for a, b, c, d, e, f, g in T.grid(N, CI, CO, OUT_H, OUT_W, K, K):\n",
    "         with T.block(\"Z\"):\n",
    "            n  = T.axis.spatial(N, a)\n",
    "            co = T.axis.spatial(CO, c)\n",
    "            dw = T.axis.spatial(OUT_W, e)\n",
    "            dh = T.axis.spatial(OUT_H, d)\n",
    "            with T.init():\n",
    "               C[n, co, dw, dh] = T.int64(0)\n",
    "      for a, b, c, d, e, f, g in T.grid(N, CI, CO, OUT_H, OUT_W, K, K):\n",
    "         with T.block(\"C\"):\n",
    "            n  = T.axis.spatial(N, a)\n",
    "            ci = T.axis.spatial(CI, b)\n",
    "            co = T.axis.spatial(CO, c)\n",
    "            dw = T.axis.spatial(OUT_W, e)\n",
    "            dh = T.axis.spatial(OUT_H, d)\n",
    "            vr = T.axis.spatial(K, f)\n",
    "            vc = T.axis.spatial(K, g)\n",
    "            C[n, co, dw, dh] = C[n, co, dw, dh] + A[n, ci, vc+dw, vr+dh] * B[co, ci, vc, vr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 474  510  546  582  618  654]\n",
      "   [ 762  798  834  870  906  942]\n",
      "   [1050 1086 1122 1158 1194 1230]\n",
      "   [1338 1374 1410 1446 1482 1518]\n",
      "   [1626 1662 1698 1734 1770 1806]\n",
      "   [1914 1950 1986 2022 2058 2094]]\n",
      "\n",
      "  [[1203 1320 1437 1554 1671 1788]\n",
      "   [2139 2256 2373 2490 2607 2724]\n",
      "   [3075 3192 3309 3426 3543 3660]\n",
      "   [4011 4128 4245 4362 4479 4596]\n",
      "   [4947 5064 5181 5298 5415 5532]\n",
      "   [5883 6000 6117 6234 6351 6468]]]]\n"
     ]
    }
   ],
   "source": [
    "rt_lib = tvm.build(MyConv, target=\"llvm\")\n",
    "data_tvm = tvm.nd.array(in1)\n",
    "weight_tvm = tvm.nd.array(in2)\n",
    "conv_tvm = tvm.nd.array(np.empty((N, CO, OUT_H, OUT_W), dtype=np.int64))\n",
    "rt_lib[\"conv\"](data_tvm, weight_tvm, conv_tvm)\n",
    "print(conv_tvm.numpy())\n",
    "np.testing.assert_allclose(conv_tvm.numpy(), conv_torch, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5.2. Section 2: How to Transform TensorIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.2.1. Parallel, Vectorize and Unroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyAdd:\n",
    "  @T.prim_func\n",
    "  def add(A: T.Buffer((4, 4), \"int64\"),\n",
    "          B: T.Buffer((4, 4), \"int64\"),\n",
    "          C: T.Buffer((4, 4), \"int64\")):\n",
    "    T.func_attr({\"global_symbol\": \"add\"})\n",
    "    for i, j in T.grid(4, 4):\n",
    "      with T.block(\"C\"):\n",
    "        vi = T.axis.spatial(4, i)\n",
    "        vj = T.axis.spatial(4, j)\n",
    "        C[vi, vj] = A[vi, vj] + B[vi, vj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = tvm.tir.Schedule(MyAdd)\n",
    "block = sch.get_block(\"C\", func_name=\"add\")\n",
    "i, j = sch.get_loops(block)\n",
    "i0, i1 = sch.split(i, factors=[2, 2])\n",
    "sch.parallel(i0)\n",
    "sch.unroll(i1)\n",
    "sch.vectorize(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">add</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), <span style=\"color: #BA2121\">&quot;int64&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), <span style=\"color: #BA2121\">&quot;int64&quot;</span>), C: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), <span style=\"color: #BA2121\">&quot;int64&quot;</span>)):\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i_0 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>parallel(<span style=\"color: #008000\">2</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> i_1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>unroll(<span style=\"color: #008000\">2</span>):\n",
       "                <span style=\"color: #008000; font-weight: bold\">for</span> j <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>vectorized(<span style=\"color: #008000\">4</span>):\n",
       "                    <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;C&quot;</span>):\n",
       "                        vi <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">4</span>, i_0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i_1)\n",
       "                        vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>spatial(<span style=\"color: #008000\">4</span>, j)\n",
       "                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[vi, vj], B[vi, vj])\n",
       "                        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(C[vi, vj])\n",
       "                        C[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> A[vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">+</span> B[vi, vj]\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm import tir</span>\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">apply_trace</span>(sch: tir<span style=\"color: #AA22FF; font-weight: bold\">.</span>Schedule) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "  b0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> sch<span style=\"color: #AA22FF; font-weight: bold\">.</span>get_block(name<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;C&quot;</span>, func_name<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;add&quot;</span>)\n",
       "  l1, l2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> sch<span style=\"color: #AA22FF; font-weight: bold\">.</span>get_loops(block<span style=\"color: #AA22FF; font-weight: bold\">=</span>b0)\n",
       "  l3, l4 <span style=\"color: #AA22FF; font-weight: bold\">=</span> sch<span style=\"color: #AA22FF; font-weight: bold\">.</span>split(loop<span style=\"color: #AA22FF; font-weight: bold\">=</span>l1, factors<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">2</span>], preserve_unit_iters<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>)\n",
       "  sch<span style=\"color: #AA22FF; font-weight: bold\">.</span>parallel(loop<span style=\"color: #AA22FF; font-weight: bold\">=</span>l3)\n",
       "  sch<span style=\"color: #AA22FF; font-weight: bold\">.</span>unroll(loop<span style=\"color: #AA22FF; font-weight: bold\">=</span>l4)\n",
       "  sch<span style=\"color: #AA22FF; font-weight: bold\">.</span>vectorize(loop<span style=\"color: #AA22FF; font-weight: bold\">=</span>l2)\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sch.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.2.2. Exercise 3: Transform a batch matmul program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low level numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnumpy_mm_relu_v2(A: np.ndarray, B: np.ndarray, C: np.ndarray):\n",
    "    Y = np.empty((16, 128, 128), dtype=\"float32\")\n",
    "    for n in range(16):\n",
    "        for i in range(128):\n",
    "            for j in range(128):\n",
    "                for k in range(128):\n",
    "                    if k == 0:\n",
    "                        Y[n, i, j] = 0\n",
    "                    Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
    "    for n in range(16):\n",
    "        for i in range(128):\n",
    "            for j in range(128):\n",
    "                C[n, i, j] = max(Y[n, i, j], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyBmmRelu:\n",
    "   @T.prim_func\n",
    "   def bmm_relu(\n",
    "      A: T.Buffer((16, 128, 128), \"float32\"), \n",
    "      B: T.Buffer((16, 128, 128), \"float32\"), \n",
    "      C: T.Buffer((16, 128, 128), \"float32\")\n",
    "   ) -> None:\n",
    "      T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
    "      Y = T.alloc_buffer((16, 128, 128), dtype=\"float32\")\n",
    "      for n, i, j, k in T.grid(16, 128, 128, 128):\n",
    "         with T.block(\"Y\"):\n",
    "            vn = T.axis.spatial(16,  n)\n",
    "            vi = T.axis.spatial(128, i)\n",
    "            vj = T.axis.spatial(128, j)\n",
    "            vk = T.axis.reduce(128,  k)\n",
    "            with T.init():\n",
    "               Y[vn, vi, vj] = T.float32(0)\n",
    "            Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
    "      for n, i, j in T.grid(16, 128, 128):\n",
    "            with T.block(\"C\"):\n",
    "               vn = T.axis.spatial(16,  n)\n",
    "               vi = T.axis.spatial(128, i)\n",
    "               vj = T.axis.spatial(128, j)\n",
    "               C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">bmm_relu</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), C: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "        Y <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer((<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>))\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> n, i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;Y&quot;</span>):\n",
       "                vn, vi, vj, vk <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSR&quot;</span>, [n, i, j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[vn, vi, vk], B[vn, vk, vj])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(Y[vn, vi, vj])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    Y[vn, vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                Y[vn, vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> Y[vn, vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[vn, vi, vk] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[vn, vk, vj]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> n, i, j <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">128</span>):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;C&quot;</span>):\n",
       "                vn, vi, vj <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSS&quot;</span>, [n, i, j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(Y[vn, vi, vj])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(C[vn, vi, vj])\n",
       "                C[vn, vi, vj] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(Y[vn, vi, vj], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm import tir</span>\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">apply_trace</span>(sch: tir<span style=\"color: #AA22FF; font-weight: bold\">.</span>Schedule) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> <span style=\"color: #008000; font-weight: bold\">None</span>:\n",
       "  <span style=\"color: #008000; font-weight: bold\">pass</span>\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sch = tvm.tir.Schedule(MyBmmRelu)\n",
    "sch.show()\n",
    "# Also please validate your result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 16\n",
    "i = 128\n",
    "k = 128\n",
    "j = 128\n",
    "input = np.arange(n*i*k).reshape(n, k, i)\n",
    "mat2  = np.arange(n*k*j).reshape(n, k, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128, 128])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_t = torch.Tensor(input)\n",
    "mat2_t  = torch.Tensor(mat2)\n",
    "bmm_torch = torch.bmm(input_t, mat2_t)\n",
    "bmmr_torch = torch.relu(bmm_torch)\n",
    "bmmr_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_it(klasse, in1, in2):\n",
    "   rt_lib = tvm.build(klasse, target=\"llvm\")\n",
    "   input_tvm = tvm.nd.array(in1)\n",
    "   mat2_tvm = tvm.nd.array(in2)\n",
    "   bmmr_tvm = tvm.nd.array(np.empty((n, i, j), dtype=np.float32))\n",
    "   rt_lib[\"bmm_relu\"](input_tvm, mat2_tvm, bmmr_tvm)\n",
    "   print(bmmr_tvm.numpy())\n",
    "   np.testing.assert_allclose(bmmr_tvm.numpy(), bmmr_torch, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[8.84326400e+07 8.84407520e+07 8.84488640e+07 ... 8.94486080e+07\n",
      "   8.94568000e+07 8.94649120e+07]\n",
      "  [2.21601792e+08 2.21626304e+08 2.21650752e+08 ... 2.24665744e+08\n",
      "   2.24690368e+08 2.24714816e+08]\n",
      "  [3.54770944e+08 3.54811936e+08 3.54852672e+08 ... 3.59882880e+08\n",
      "   3.59923904e+08 3.59964640e+08]\n",
      "  ...\n",
      "  [1.67345684e+10 1.67366349e+10 1.67386941e+10 ... 1.69915945e+10\n",
      "   1.69936527e+10 1.69957089e+10]\n",
      "  [1.68677376e+10 1.68698194e+10 1.68718950e+10 ... 1.71268086e+10\n",
      "   1.71288883e+10 1.71309548e+10]\n",
      "  [1.70009068e+10 1.70029978e+10 1.70050888e+10 ... 1.72620308e+10\n",
      "   1.72641198e+10 1.72662088e+10]]\n",
      "\n",
      " [[5.16269834e+10 5.16291011e+10 5.16311982e+10 ... 5.18901514e+10\n",
      "   5.18922609e+10 5.18943580e+10]\n",
      "  [5.20285880e+10 5.20307139e+10 5.20328151e+10 ... 5.22938040e+10\n",
      "   5.22959258e+10 5.22980557e+10]\n",
      "  [5.24301926e+10 5.24323226e+10 5.24344607e+10 ... 5.26974566e+10\n",
      "   5.26995988e+10 5.27017247e+10]\n",
      "  ...\n",
      "  [1.01827576e+11 1.01831705e+11 1.01835866e+11 ... 1.02346736e+11\n",
      "   1.02350889e+11 1.02355042e+11]\n",
      "  [1.02229180e+11 1.02233326e+11 1.02237503e+11 ... 1.02750388e+11\n",
      "   1.02754550e+11 1.02758719e+11]\n",
      "  [1.02630785e+11 1.02634971e+11 1.02639149e+11 ... 1.03154041e+11\n",
      "   1.03158227e+11 1.03162405e+11]]\n",
      "\n",
      " [[1.71885036e+11 1.71889230e+11 1.71893424e+11 ... 1.72410339e+11\n",
      "   1.72414534e+11 1.72418728e+11]\n",
      "  [1.72555076e+11 1.72559286e+11 1.72563481e+11 ... 1.73082427e+11\n",
      "   1.73086638e+11 1.73090849e+11]\n",
      "  [1.73225116e+11 1.73229326e+11 1.73233521e+11 ... 1.73754499e+11\n",
      "   1.73758743e+11 1.73762970e+11]\n",
      "  ...\n",
      "  [2.55640076e+11 2.55646269e+11 2.55652463e+11 ... 2.56421298e+11\n",
      "   2.56427540e+11 2.56433783e+11]\n",
      "  [2.56310116e+11 2.56316326e+11 2.56322601e+11 ... 2.57093386e+11\n",
      "   2.57099645e+11 2.57105904e+11]\n",
      "  [2.56980156e+11 2.56986399e+11 2.56992707e+11 ... 2.57765458e+11\n",
      "   2.57771733e+11 2.57778024e+11]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[6.03020958e+12 6.03023737e+12 6.03026358e+12 ... 6.03361798e+12\n",
      "   6.03364419e+12 6.03367145e+12]\n",
      "  [6.03383451e+12 6.03385915e+12 6.03388484e+12 ... 6.03724133e+12\n",
      "   6.03726807e+12 6.03729638e+12]\n",
      "  [6.03745262e+12 6.03748250e+12 6.03751344e+12 ... 6.04086993e+12\n",
      "   6.04090034e+12 6.04091974e+12]\n",
      "  ...\n",
      "  [6.48306334e+12 6.48309165e+12 6.48312101e+12 ... 6.48672707e+12\n",
      "   6.48675695e+12 6.48678631e+12]\n",
      "  [6.48668670e+12 6.48671501e+12 6.48674384e+12 ... 6.49035252e+12\n",
      "   6.49038083e+12 6.49041176e+12]\n",
      "  [6.49030848e+12 6.49033784e+12 6.49036720e+12 ... 6.49397744e+12\n",
      "   6.49400680e+12 6.49403564e+12]]\n",
      "\n",
      " [[6.97510239e+12 6.97512860e+12 6.97515796e+12 ... 6.97877240e+12\n",
      "   6.97880124e+12 6.97883112e+12]\n",
      "  [6.97899155e+12 6.97902301e+12 6.97905290e+12 ... 6.98266576e+12\n",
      "   6.98269093e+12 6.98272029e+12]\n",
      "  [6.98288387e+12 6.98291323e+12 6.98294259e+12 ... 6.98655808e+12\n",
      "   6.98658796e+12 6.98661627e+12]\n",
      "  ...\n",
      "  [7.46150953e+12 7.46153889e+12 7.46157244e+12 ... 7.46543592e+12\n",
      "   7.46546790e+12 7.46549726e+12]\n",
      "  [7.46540027e+12 7.46543173e+12 7.46546266e+12 ... 7.46932929e+12\n",
      "   7.46936074e+12 7.46939168e+12]\n",
      "  [7.46929258e+12 7.46932299e+12 7.46935393e+12 ... 7.47322212e+12\n",
      "   7.47325358e+12 7.47328556e+12]]\n",
      "\n",
      " [[7.98871205e+12 7.98874403e+12 7.98877496e+12 ... 7.99264316e+12\n",
      "   7.99267462e+12 7.99270712e+12]\n",
      "  [7.99287175e+12 7.99290320e+12 7.99293519e+12 ... 7.99680653e+12\n",
      "   7.99683799e+12 7.99686892e+12]\n",
      "  [7.99703040e+12 7.99706343e+12 7.99709436e+12 ... 8.00096833e+12\n",
      "   8.00100031e+12 8.00103177e+12]\n",
      "  ...\n",
      "  [8.50867467e+12 8.50870823e+12 8.50874178e+12 ... 8.51286478e+12\n",
      "   8.51289676e+12 8.51293136e+12]\n",
      "  [8.51283542e+12 8.51286793e+12 8.51290253e+12 ... 8.51702605e+12\n",
      "   8.51705856e+12 8.51709316e+12]\n",
      "  [8.51699565e+12 8.51702815e+12 8.51706275e+12 ... 8.52118785e+12\n",
      "   8.52122246e+12 8.52125549e+12]]]\n"
     ]
    }
   ],
   "source": [
    "test_it(MyBmmRelu, input_t, mat2_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
